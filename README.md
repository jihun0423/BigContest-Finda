# 핀다 앱 사용성 데이터를 통한 대출 여부 예측 
빅콘테스트 퓨처스리그
https://www.bigcontest.or.kr/points/content.php#ct04


<br />



# 1. 참여 계기  
빅콘테스트에서 개최한 데이터분석 퓨처스리그의 핀다앱 사용성 데이터를 통한 대출 여부 예측을 팀 프로젝트로 하기로 하였다.  
최종 정리 및 발표 자료는 pdf 파일에 저장하였다.


<br />




# 2. 참여 인원 / 기간
* 팀 프로젝트 (4인)
* 2022년 9월 1일 ~ 2023년 12월 1일


<br />




# 3. 사용 기술
* Python
* SQL
* Matplotlib
* Sklearn


<br />



# 4. 작업 환경
* Jupyter Notebook (CPU)
* Google Colab (GPU)


<br />



# 5. 프로젝트 진행 과정
<br />



## 1. 데이터 확인 및 전처리
* 데이터 셋은 총 2가지가 있는데, 핀다 앱을 통해 신청한 대출 신청 여부에 대한 데이터 Loan_result와, 가명화된 핀다 앱 사용자의 개인정보 User_spec이 있다.
* 타겟의 분포를 확인하였더니, 대출 여부 (is_applied) 불균형이 매우 심한걸로 나타나 불균형을 어떻게 처리하는지가 관건일 것으로 보였다.
* 각 데이터 셋에 대하여 결측치 처리를 해 주었다. 대체할 수 있는 (유추가 가능한) 결측치는 대체를 해 주었고, 유추가 불가능한 결측치는 제거를 해 주었다.
* 돈과 관련된 컬럼들은 분포가 매우 치우쳐 있어 머신러닝의 효과를 높이기 위하여 정규분포에 최대한 가깝게 되도록 변환을 해주었다.
* 전처리를 완료한 2가지 데이터 셋을 합쳐 하나의 데이터 셋으로 만들었다.


* 전처리 코드는 preprocessing.ipynb 


<br />


## 2. EDA 및 불필요한 컬럼 제거
* 범주형, 연속형 변수들을 타겟 컬럼과 연관지어 시각화 및 상관관계를 알아보았다. 대부분의 컬럼들이 타겟과의 상관관계가 거의 없다고 나왔다. 타겟의 불균형이 매우 심해서 그렇다고 생각한다.
* 이번 프로젝트의 EDA에서 가장 중요한 점은 어떤 컬럼을 머신러닝에 사용할지 정하는 것이였다. EDA.ipynb 파일의 맨 뒤에 기술 하였듯이, 이번 데이터들에서는 신용할 수 없는 데이터들이 굉장히 많았다. 이러한 변수들을 제거하여 신용할 수 있는 변수들만 남겨두었다.


* EDA 및 불필요한 컬럼 제거.ipynb 참조


<br />


## 3. 표준화 및 PCA
* 머신러닝을 통하여 학습할 때, 컬럼별로 숫자의 범위가 다를 경우 학습할 때 지장이 있을 수 있다. 따라서, 모든 연속형 변수에 대하여 Min-Max Scaler를 통해 0~1 범위로 맞추어주었다.
* PCA는 차원 축소를 통하여 데이터를 더 낮은 차원의 데이터로 정보를 함축시킨다. 머신러닝에 있어서 컬럼 수가 많을 수록, 성능이 저하될 수 있기에 차원 축소를 해 주었다.


* 표준화 및 pca.ipynb 참조


## 4. 불균형 해소
* 앞서 언급했듯이, 타겟 데이터의 불균형이 매우 심각하다 (93 : 7). 따라서, 불균형을 해소하기 위해 여러 방법을 사용하였다.  


1. 언더샘플링
* 데이터 수가 많은 라벨에 대하여 데이터 수를 줄여 균형을 맞추는 방법이다.  
이번 데이터 셋에는 800만개가 넘는 데이터가 있으므로, 언더샘플링을 해도 데이터 수는 충분히 많을 수도 있다고 생각해 진행을 해 보았다.   
하지만, 언더샘플링은 다수 데이터를 대부분 쓰지 않는 다는 것과 같으므로 데이터의 손실이 일어나 되려 성능이 안 좋아 질수도 있다.


2. 오버 샘플링
* 데이터 수가 적은 라벨에 대하여 데이터 수를 늘려 균형을 맞추는 방법이다.  
오버샘플링은 데이터 수가 적은 라벨의 데이터들을 최근접 이웃을 사용하여 새로운 데이터를 생성해 데이터 수를 늘린다.  
오버샘플링을 사용할 경우 데이터 수가 기존의 거의 2배가 되므로 더욱 더 정교한 학습이 가능해진다.  
하지만, 적은 수의 데이터를 이용하여 새로 데이터를 만든 것이므로, 이 적은 수의 데이터의 범주에 과적합이 될 가능성이 있다. 또한, 데이터 수가 굉장히 많아지므로 학습하는데 시간도 매우 오래 걸린다.

* 위의 2가지 방법과 불균형을 해소하지 않은 채 원본 데이터 그대로, 총 3가지의 방법으로 기본적인 머신러닝 모델을 돌려본 결과, 오버샘플링이 가장 성능이 좋게 나왔다.  
따라서, 오버샘플링으로 진행하기로 결정하고, 다양한 오버샘플링 기법들을 이용하여 가장 좋은 결과를 낸 오버샘플링 기법을 채용하였다. (Smotetomek)


* 오버샘플링,언더샘플링.ipynb 참조


<br />


## 5. 모델 설정 및 그리드 서치
* 여러가지 머신러닝 모델들을 사용하였다. Pycaret을 이용한 AutoML로 적합한 모델을 먼저 찾고 싶었지만, 데이터 수가 매우 커서 시간이 매우 오래 걸려 할 수 없었다.
* GPU 가속이 가능한 부스팅 모델들을 위주로 그리드 서치를 해 주었다.
* 평가 기준인 f1-score을 기준으로 가장 결과가 좋았던 모델은 랜덤 포레스트이다.


<br />


## 6. 앙상블
* 앞서 사용한 모델들 중, 상위 3개의 모델을 이용하여 소프트 보팅, 하드 보팅 앙상블을 하였다.
* 또한, 모델들의 예측값들을 다시 학습 데이터로 활용하여 학습하는 스태킹 앙상블도 사용하였다. 


<br />



# 7. 결과
* 평가 기준은 f1-Score로, Baseline에서 주어진 스코어는 0.24 였다.
* 가장 f1-score가 높게 나왔던 스태킹 앙상블 모델의 결과는 0.364로, Baseline보다 성능이 많이 향상되었음을 확인할 수 있었다.



<br />



# 7. 회고 / 느낀점
* 이번 프로젝트에서 가장 관건은 대량의 불균형 데이터를 어떻게 처리하는지가 관건이였던 것 같다. 여러가지 오버샘플링 기법들을 통하여 적절한 방법을 찾은 것 같아서 좋았다.
* 부족하다고 느낀점은 여럿 있는데, EDA 및 데이터 탐색을 좀 더 자세하게 했었어야 했다고 생각한다. 신용할 수 있는 컬럼들에 대해서만 신경을 쓴 나머지, 자세하게 데이터를 들여다보지 않은 것 같다.
* 또한, 좀 더 다양한 모델들, 그리고 그리드 서치를 더 다양하게 했어야 한다고 생각한다. 스태킹을 통하여 성능을 향상 시킨것은 기뻤으나, 스태킹에 사용된 모델들이 좀 더 성능이 좋았더라면 더 결과가 좋지 않았을까 하는 생각도 든다. 데이터 수가 매우 많아서 (1600만개 이상) 학습에 시간이 오래 걸리다보니 시간이 부족하여 그리드 서치를 더 세부적으로 하지 못한게 아쉬웠다. 


<br />



# 파일 순서
preprocessing -> EDA -> 표준화,PCA -> 오버샘플링 -> 모델링 -> 앙상블
